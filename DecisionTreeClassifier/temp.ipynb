{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./data/nursery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parents             12960\n",
       "has_nurs            12960\n",
       "form                12960\n",
       "children            12960\n",
       "housing             12960\n",
       "finance             12960\n",
       "social              12960\n",
       "health              12960\n",
       "final evaluation    12960\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing data in the dataset. So, we can directly move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =  data['final evaluation']\n",
    "X = data.drop(labels=['final evaluation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, impurity='entropy'):\n",
    "        self.max_depth = max_depth\n",
    "        self.impurity_name = impurity\n",
    "        self.decision_tree_pathes = None\n",
    "\n",
    "        if impurity == 'entropy':\n",
    "            self.impurity = self.entropy\n",
    "\n",
    "        elif impurity == 'gini':\n",
    "            self.impurity = self.gini\n",
    "\n",
    "    def encode_X(self, X):\n",
    "        return np.array(X.apply(LabelEncoder().fit_transform))\n",
    "\n",
    "    def encode_y(self, y):\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        return self.label_encoder.fit_transform(y)\n",
    "\n",
    "    def decode_y(self, y):\n",
    "\n",
    "        if self.label_encoder is None:\n",
    "            raise Exception('Label encoder is not initialized')\n",
    "\n",
    "        return self.label_encdoer.inverse_transform(y)\n",
    "\n",
    "    def probablity(self, X):\n",
    "        return np.unique(X,return_counts=True)[1]/X.shape[0]\n",
    "\n",
    "    def entropy(self, X):\n",
    "        X = self.probablity(X)\n",
    "\n",
    "        return np.dot(X, -np.log2(X))\n",
    "\n",
    "    def gini(self, X):\n",
    "        X = self.probablity(X)\n",
    "        return 1 - np.dot(X, X)\n",
    "\n",
    "    def information_gain(self, X, y):\n",
    "\n",
    "        if len(X.shape) == 1:\n",
    "            np.expand_dims(X, axis=1)\n",
    "\n",
    "        info_gain = list()\n",
    "        for i in range(X.shape[1]):\n",
    "            X1 = X[:, i]\n",
    "            info_gain.append(self.impurity(y)\n",
    "                             - np.sum(\n",
    "                                 [self.probablity(X1)[j] *\n",
    "                                  self.impurity(y[X1 == j])\n",
    "                                  for j in np.unique(X1)]))\n",
    "\n",
    "        return np.array(info_gain)\n",
    "\n",
    "    def split_nodes(self, X, y):\n",
    "\n",
    "        feature_arg = np.argmax(self.information_gain(X, y))\n",
    "        X1 = X[:, feature_arg]\n",
    "        X = np.delete(X, feature_arg, axis=1)\n",
    "\n",
    "        return [(X[X1 == i], y[X1 == i]) for i in np.unique(X1)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = self.encode_X(X)\n",
    "        y = self.encode_y(y)\n",
    "\n",
    "        if len(X.shape) == 1:\n",
    "            X = np.expand_dims(X, axis=1)\n",
    "\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = X.shape[1]\n",
    "\n",
    "        Xs_ys = self.split_nodes(X, y)\n",
    "        for _ in range(self.max_depth-1):\n",
    "            Xs_ys_new = list()\n",
    "            for i in range(len(Xs_ys)):\n",
    "                Xs_ys_new += self.split_nodes(Xs_ys[i][0], Xs_ys[i][1])\n",
    "\n",
    "            Xs_ys = Xs_ys_new\n",
    "\n",
    "        return Xs_ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33275463, 0.33246528, 0.33478009])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.probablity(X_train_encoded[:,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=None)\n",
    "X_train_encoded = model.encode_X(X_train)\n",
    "y_train_encoded = model.encode_y(y_train)\n",
    "# model.fit(X_train,y_train)\n",
    "# model.information_gain(X_train_encoded,y_train_encoded)\n",
    "# model.probablity(X_train_encoded[:,7])\n",
    "# model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b48bd92917a400be1b39f4e6f0c911d2a30a3918a0ff2492a6880d1654b5ed5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
